{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import os.path as osp\n",
    "import random\n",
    "import math\n",
    "import multiprocessing as mp\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import timm\n",
    "\n",
    "pl.seed_everything(42)\n",
    "\n",
    "preprocess_data = False\n",
    "calibrate_data = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_PATH = \"/mnt/elice/dataset\"\n",
    "PREPROCESSED_PATH = \"/home/elicer/data\"\n",
    "\n",
    "def preprocess_worker(path):\n",
    "    global face_classifier\n",
    "    if \"face_classifier\" not in globals():\n",
    "        face_classifier = cv2.CascadeClassifier(\n",
    "            cv2.data.a + \"haarcascade_frontalface_default.xml\"\n",
    "        )\n",
    "        \n",
    "    cap = cv2.VideoCapture(path[0])\n",
    "    \n",
    "    if osp.isfile(path[1]):\n",
    "        return\n",
    "    \n",
    "    output = cv2.VideoWriter(path[1], cv2.VideoWriter_fourcc('m', 'p', '4', 'v'), cap.get(cv2.CAP_PROP_FPS), (224, 224))\n",
    "    \n",
    "    _, frame = cap.read()\n",
    "    frame = cv2.resize(frame, None, fx=1, fy=10/16)\n",
    "    face_region = face_classifier.detectMultiScale(cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY))\n",
    "    area = [w * h for _, _, w, h in face_region]\n",
    "    \n",
    "    while len(area) == 0  or max(area) == 0:\n",
    "        _, frame = cap.read()\n",
    "        frame = cv2.resize(frame, None, fx=1, fy=10/16)\n",
    "        face_region = face_classifier.detectMultiScale(cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY))\n",
    "        area = [w * h for _, _, w, h in face_region]\n",
    "    \n",
    "    face_region = face_region[area.index(max(area))]\n",
    "\n",
    "    padding_ratio = 1.2\n",
    "    x, y, w, h = face_region\n",
    "    center_x, center_y = x + w // 2, y + h // 2\n",
    "    w, h = w * padding_ratio, h * padding_ratio\n",
    "    x, y = max(center_x - w // 2, 0) , max(center_y - h // 2, 0)\n",
    "\n",
    "    count = 0\n",
    "    while (cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame = cv2.resize(frame, None, fx=1, fy=10/16)\n",
    "        frame = frame[int(y):int(y + h), int(x):int(x + w)]\n",
    "\n",
    "        frame = cv2.resize(frame, (224, 224))\n",
    "        \n",
    "        count += 1\n",
    "        output.write(frame)\n",
    "        \n",
    "        if count == 30 * 30:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    output.release()\n",
    "\n",
    "def preprocess(data_type):\n",
    "    if data_type == \"train\":\n",
    "        canditate = [\"real\"]\n",
    "    else:\n",
    "        canditate = \".\"\n",
    "    \n",
    "    for label in canditate:\n",
    "        raw_path = osp.join(RAW_PATH, data_type, label)\n",
    "        preprocessed_path = osp.join(PREPROCESSED_PATH, data_type, label)\n",
    "\n",
    "        if not osp.exists(preprocessed_path):\n",
    "            os.makedirs(preprocessed_path)\n",
    "\n",
    "        raw_paths = glob.glob(osp.join(raw_path, \"*\"))\n",
    "        preprocess_paths = [osp.join(preprocessed_path, osp.basename(path)) for path in raw_paths]\n",
    "\n",
    "        with mp.Pool(mp.cpu_count() - 2) as pool:\n",
    "            list(tqdm(pool.imap(preprocess_worker, zip(raw_paths, preprocess_paths)), total=len(raw_paths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if preprocess_data:\n",
    "    preprocess(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if preprocess_data:\n",
    "    preprocess(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "if preprocess_data:\n",
    "    for label in [\"fake\", \"real\"]:\n",
    "        train_path = osp.join(PREPROCESSED_PATH, \"train\", label)\n",
    "        val_path = osp.join(PREPROCESSED_PATH, \"val\", label)\n",
    "\n",
    "        if not osp.exists(val_path):\n",
    "            os.makedirs(val_path)\n",
    "\n",
    "        train_paths = glob.glob(osp.join(train_path, \"*\"))\n",
    "        val_paths = train_paths[: int(len(train_paths) * 0.1)]\n",
    "\n",
    "        for path in val_paths:\n",
    "            shutil.move(path, path.replace(\"train\", \"val\"))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from facenet_pytorch import MTCNN\n",
    "\n",
    "\n",
    "def calibrate_worker(path):\n",
    "    global face_classifier\n",
    "    if \"face_classifier\" not in globals():\n",
    "        face_classifier = MTCNN(device=\"cuda\")\n",
    "    \n",
    "    cap = cv2.VideoCapture(path[0])\n",
    "    \n",
    "    if osp.isfile(path[1]):\n",
    "        return\n",
    "    \n",
    "    output = cv2.VideoWriter(path[1], cv2.VideoWriter_fourcc('m', 'p', '4', 'v'), cap.get(cv2.CAP_PROP_FPS), (224, 224))\n",
    "    \n",
    "    _, frame = cap.read()\n",
    "    frame = cv2.resize(frame, None, fx=1, fy=12/16)\n",
    "    face_region = face_classifier.detect(np.expand_dims(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB), axis=0))\n",
    "    \n",
    "    if face_region[0][0] is None:\n",
    "        face_region = [[[[0, 0, 480, 480]]]]\n",
    "    face_region = face_region[0][0][0]\n",
    "\n",
    "    padding_ratio = 1.4\n",
    "    x1, y1, x2, y2 = face_region\n",
    "    \n",
    "    x, y, w, h = x1, y1, x2 - x1, y2 - y1\n",
    "    center_x, center_y = x + w // 2, y + h // 2\n",
    "    w, h = w * padding_ratio, h * padding_ratio\n",
    "    x, y = max(center_x - w // 2, 0) , max(center_y - h // 2, 0)\n",
    "\n",
    "    count = 0\n",
    "    while (cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame = cv2.resize(frame, None, fx=1, fy=12/16)\n",
    "        frame = frame[int(y):int(y + h), int(x):int(x + w)]\n",
    "\n",
    "        frame = cv2.resize(frame, (224, 224))\n",
    "        \n",
    "        count += 1\n",
    "        output.write(frame)\n",
    "        \n",
    "        if count == 30 * 30:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    output.release()\n",
    "\n",
    "def calibrate(data_type):\n",
    "    if data_type != \"test\":\n",
    "        canditate = [\"fake\", \"real\"]\n",
    "    else:\n",
    "        canditate = \".\"\n",
    "    \n",
    "    for label in canditate:\n",
    "        fault_file = f\"/home/elicer/data/fault_{data_type}_{label}.txt\" if data_type != \"test\" else f\"/home/elicer/data/fault_test.txt\"\n",
    "        fault_paths = []\n",
    "        with open(fault_file) as f:\n",
    "            for line in f:\n",
    "                fault_paths.append(line.strip())\n",
    "        \n",
    "        fault_folder = \"train\" if data_type == \"val\" else data_type\n",
    "        fault_paths = [osp.join(RAW_PATH, fault_folder, label, file + \".mp4\") for file in fault_paths]\n",
    "\n",
    "        calibrate_path = osp.join(PREPROCESSED_PATH, f\"calibrate_{data_type}\", label)\n",
    "\n",
    "        if not osp.exists(calibrate_path):\n",
    "            os.makedirs(calibrate_path)\n",
    "\n",
    "        calibrate_paths = [osp.join(calibrate_path, osp.basename(path)) for path in fault_paths]\n",
    "\n",
    "        with mp.Pool(mp.cpu_count() - 2) as pool:\n",
    "            list(tqdm(pool.imap(calibrate_worker, zip(fault_paths, calibrate_paths)), total=len(fault_paths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if calibrate_data:\n",
    "    calibrate(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if calibrate_data:\n",
    "    for label in [\"real\", \"fake\"]:\n",
    "        calibrate_path = osp.join(PREPROCESSED_PATH, \"calibrate_train\", label)\n",
    "        calibrate_paths = glob.glob(osp.join(calibrate_path, \"*\"))\n",
    "        for path in calibrate_paths:\n",
    "            shutil.move(path, path.replace(\"calibrate_train\", \"train\"))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if calibrate_data:\n",
    "    calibrate(\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if calibrate_data:\n",
    "    for label in [\"real\", \"fake\"]:\n",
    "        calibrate_path = osp.join(PREPROCESSED_PATH, \"calibrate_val\", label)\n",
    "        calibrate_paths = glob.glob(osp.join(calibrate_path, \"*\"))\n",
    "        for path in calibrate_paths:\n",
    "            shutil.move(path, path.replace(\"calibrate_val\", \"val\"))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if calibrate_data:\n",
    "    calibrate(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if calibrate_data:\n",
    "    calibrate_path = osp.join(PREPROCESSED_PATH, \"calibrate\")\n",
    "    test_path = osp.join(PREPROCESSED_PATH, \"test\")\n",
    "\n",
    "    calibrate_paths = glob.glob(osp.join(calibrate_path, \"*\"))\n",
    "    for path in calibrate_paths:\n",
    "        shutil.move(path, path.replace(\"calibrate\", \"test\"))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset & Data Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torchvision.io import read_video\n",
    "\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, config, data_type, transform=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.config = config\n",
    "        self.data_type = data_type\n",
    "        self.transform = transform\n",
    "\n",
    "        if self.data_type != \"test\":\n",
    "            fake_paths = glob.glob(osp.join(PREPROCESSED_PATH, data_type, \"fake\", \"*\"))\n",
    "            real_paths = glob.glob(osp.join(PREPROCESSED_PATH, data_type, \"real\", \"*\"))\n",
    "\n",
    "            self.paths = fake_paths + real_paths\n",
    "            self.labels = [1] * len(fake_paths) + [0] * len(real_paths)\n",
    "            \n",
    "        else:\n",
    "            self.paths = sorted(glob.glob(osp.join(PREPROCESSED_PATH, data_type, \"*\")))\n",
    "            self.labels = [1] * len(self.paths)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx, start_time, end_time = self._get_interval(idx)\n",
    "\n",
    "        video = read_video(self.paths[idx], start_time, end_time, output_format=\"TCHW\", pts_unit=\"sec\")[0]\n",
    "        label = torch.tensor(self.labels[idx])\n",
    "        \n",
    "        if self.transform:\n",
    "            video = self.transform(video)\n",
    "            \n",
    "        if random.random() > 0.5:\n",
    "            video = video.flip(dims=[3])\n",
    "            \n",
    "        video = video[random.sample(range(video.shape[0]), self.config[\"num_timesteps\"])]\n",
    "        return video, label\n",
    "    \n",
    "    def _get_interval(self, idx, alpha=1.8):\n",
    "        cap = cv2.VideoCapture(self.paths[idx])\n",
    "        frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))      \n",
    "        cap.release()\n",
    "        \n",
    "        if self.data_type != \"test\":\n",
    "            while frame_count - int(self.config[\"num_timesteps\"] * alpha) <= 0:\n",
    "                idx = (idx + 1) % len(self.paths)\n",
    "                cap = cv2.VideoCapture(self.paths[idx])\n",
    "                frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "                frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "                cap.release()\n",
    "        \n",
    "        start_index = random.randint(0, frame_count - int(self.config[\"num_timesteps\"] * alpha))\n",
    "        start_time = start_index / frame_rate\n",
    "        end_time = min(start_index + int(self.config[\"num_timesteps\"] * alpha), frame_count) / frame_rate\n",
    "        \n",
    "        return idx, start_time, end_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "class CustomDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.batch_size = config[\"batch_size\"]\n",
    "        self.num_workers = config[\"num_workers\"]\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ConvertImageDtype(torch.float32),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "        \n",
    "        self.train_dataset = CustomDataset(config, \"train\", transform=transform)\n",
    "        self.val_dataset = CustomDataset(config, \"val\", transform=transform)\n",
    "        self.test_dataset = CustomDataset(config, \"test\", transform=transform)\n",
    "\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=True,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=False,\n",
    "        )\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=False,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 64):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(1, 0, 2)\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        x = x.permute(1, 0, 2)\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class TemporalTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_heads, num_layers):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, input_dim))\n",
    "        self.pos_encoder = PositionalEncoding(input_dim)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            input_dim, \n",
    "            dim_feedforward=hidden_dim, \n",
    "            nhead=num_heads, \n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.classifier = nn.Linear(input_dim, 1)\n",
    "        \n",
    "\n",
    "    def forward(self, x, order):\n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        for _ in range(order):\n",
    "            x = x[:, 1:] - x[:, :-1]\n",
    "        \n",
    "        cls_tokens = self.cls_token.expand(batch_size, -1, -1)\n",
    "        \n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "        x = self.pos_encoder(x)\n",
    "        output = self.transformer_encoder(x)[:, 0]\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "class CustomModel(pl.LightningModule):\n",
    "    def __init__(self, feature_dim=256, hidden_dim=512, nhead=4):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.feature_extractor = timm.create_model(\"efficientnet_b2\", pretrained=True, num_classes=feature_dim)\n",
    "        self.temporal_transformer = TemporalTransformer(feature_dim, hidden_dim, num_heads=nhead, num_layers=2)\n",
    "        self.classifier = nn.Linear(feature_dim, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        b, t, c, h, w = x.shape\n",
    "        \n",
    "        x = x.view(b * t, c, h, w)\n",
    "        x = self.feature_extractor(x)\n",
    "        x = x.view(b, t, -1)\n",
    "        \n",
    "        x = self.temporal_transformer(x, order=1)\n",
    "        output = self.classifier(x)\n",
    "        return output\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        data, label = batch\n",
    "        pred = self(data).reshape(-1)\n",
    "        \n",
    "        loss = F.binary_cross_entropy_with_logits(pred, label.float())\n",
    "        self.log(\"train loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        data, label = batch\n",
    "        pred = (torch.sigmoid(self(data)) > 0.5).reshape(-1)\n",
    "        \n",
    "        score = (pred == label).float().mean()\n",
    "        self.log(\"val score\", score, prog_bar=True)\n",
    "        return score\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(self.parameters(), lr=1e-5)\n",
    "        scheduler = optim.lr_scheduler.MultiplicativeLR(\n",
    "            optimizer=optimizer,\n",
    "            lr_lambda=lambda epoch: 0.80 ** epoch\n",
    "        )\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"batch_size\" : 12, \n",
    "    \"num_workers\" : 6, \n",
    "    \n",
    "    \"num_timesteps\": 16, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = CustomDataModule(config)\n",
    "model = CustomModel()\n",
    "model.load_state_dict(torch.load(\"/home/elicer/weight/final.ckpt\")[\"state_dict\"])\n",
    "\n",
    "torch.set_float32_matmul_precision(\"medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "2023-11-30 22:10:19.294251: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-30 22:10:19.434417: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-30 22:10:20.550101: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/elicer/.local/lib/python3.10/site-packages/cv2/../../lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-11-30 22:10:20.550166: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/elicer/.local/lib/python3.10/site-packages/cv2/../../lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-11-30 22:10:20.550174: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                 | Type                | Params\n",
      "-------------------------------------------------------------\n",
      "0 | feature_extractor    | EfficientNet        | 8.1 M \n",
      "1 | temporal_transformer | TemporalTransformer | 1.1 M \n",
      "2 | classifier           | Linear              | 257   \n",
      "-------------------------------------------------------------\n",
      "9.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "9.1 M     Total params\n",
      "36.467    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86332f264ec14a2991c799dae7e62e5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x5645ebd17940] moov atom not found\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x5645ebd17940] moov atom not found\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x5645ebd17940] moov atom not found\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x5645ebd17940] moov atom not found\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x5645ee3c6c00] moov atom not found\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x5645ec1fce00] moov atom not found\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x5645ece4e100] moov atom not found\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x5645ebd5f880] moov atom not found\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x5645ebdffbc0] moov atom not found\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x5645eed7edc0] moov atom not found\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x5645f6c11c40] moov atom not found\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x5645ec4b8ac0] moov atom not found\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x5645ed163080] moov atom not found\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x5645ee162200] moov atom not found\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x5645ecf9ef40] moov atom not found\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x5645ecf9ef40] moov atom not found\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x5645f0914dc0] moov atom not found\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x5645ee32a940] moov atom not found\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x5645ee32a940] moov atom not found\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x5645ee32a940] moov atom not found\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x5645ec496480] moov atom not found\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x5645ed274040] moov atom not found\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x5645ed274040] moov atom not found\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x5645ec496480] moov atom not found\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x5645ed2cb100] moov atom not found\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x5645ecf9ef40] moov atom not found\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x5645ed3ba100] moov atom not found\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x5645ecfca580] moov atom not found\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x5645ed2c2080] moov atom not found\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x5645ee4fb200] moov atom not found\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x5645ee15d740] moov atom not found\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x5645f6ae75c0] moov atom not found\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x5645f6ae75c0] moov atom not found\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x5645ed4b0340] moov atom not found\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x5645ee15d740] moov atom not found\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x5645ed270480] moov atom not found\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x5645ee329fc0] moov atom not found\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x5645ec4fb900] moov atom not found\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x5645ee329fc0] moov atom not found\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x5645ec4fb900] moov atom not found\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x5645ed2688c0] moov atom not found\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x5645ed2688c0] moov atom not found\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x5645ed2688c0] moov atom not found\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x5645ec5d6140] moov atom not found\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x5645f6ba9500] moov atom not found\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x5645ee5d6a00] moov atom not found\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x5645ee28ce40] moov atom not found\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x5645f6d515c0] moov atom not found\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x5645f9436340] moov atom not found\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x5645f9436340] moov atom not found\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    max_epochs=5, \n",
    "    log_every_n_steps=10, \n",
    "    val_check_interval=300,\n",
    "    precision=\"16-mixed\",\n",
    "    accelerator=\"gpu\",\n",
    ")\n",
    "\n",
    "model.train()\n",
    "trainer.fit(model, datamodule=datamodule)\n",
    "# trainer.fit(model, datamodule=datamodule, ckpt_path=\"/home/elicer/lightning_logs/version_116/checkpoints/epoch=1-step=825.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "current_time = time.time()\n",
    "trainer.save_checkpoint(osp.join(\"/home/elicer/weight\", f\"{current_time}.ckpt\"), weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "submission = pd.read_csv(\"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = CustomDataModule(config)\n",
    "datamodule.setup()\n",
    "test_dataloader = datamodule.test_dataloader()\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomModel(\n",
       "  (feature_extractor): EfficientNet(\n",
       "    (conv_stem): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNormAct2d(\n",
       "      32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "      (drop): Identity()\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (blocks): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): DepthwiseSeparableConv(\n",
       "          (conv_dw): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pw): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): DepthwiseSeparableConv(\n",
       "          (conv_dw): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(16, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(4, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pw): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): InvertedResidual(\n",
       "          (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): InvertedResidual(\n",
       "          (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(528, 22, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(22, 528, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): InvertedResidual(\n",
       "          (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(528, 22, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(22, 528, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (3): InvertedResidual(\n",
       "          (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(528, 22, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(22, 528, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(528, 528, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=528, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(528, 22, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(22, 528, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(528, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(720, 720, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=720, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(720, 30, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(30, 720, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(720, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): InvertedResidual(\n",
       "          (conv_pw): Conv2d(120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(720, 720, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=720, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(720, 30, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(30, 720, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(720, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (3): InvertedResidual(\n",
       "          (conv_pw): Conv2d(120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(720, 720, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=720, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(720, 30, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(30, 720, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(720, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(720, 720, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=720, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(720, 30, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(30, 720, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(720, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(1248, 1248, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1248, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1248, 52, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(52, 1248, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1248, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): InvertedResidual(\n",
       "          (conv_pw): Conv2d(208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(1248, 1248, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1248, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1248, 52, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(52, 1248, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1248, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (3): InvertedResidual(\n",
       "          (conv_pw): Conv2d(208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(1248, 1248, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1248, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1248, 52, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(52, 1248, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1248, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (4): InvertedResidual(\n",
       "          (conv_pw): Conv2d(208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(1248, 1248, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1248, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1248, 52, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(52, 1248, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1248, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "      (6): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(1248, 1248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1248, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1248, 52, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(52, 1248, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1248, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(352, 2112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            2112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(2112, 2112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2112, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            2112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(2112, 88, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(88, 2112, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(2112, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (conv_head): Conv2d(352, 1408, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn2): BatchNormAct2d(\n",
       "      1408, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "      (drop): Identity()\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
       "    (classifier): Linear(in_features=1408, out_features=256, bias=True)\n",
       "  )\n",
       "  (temporal_transformer): TemporalTransformer(\n",
       "    (pos_encoder): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer_encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (classifier): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = current_time\n",
    "# model_name = \"1701366401.355616\"\n",
    "\n",
    "model = CustomModel.load_from_checkpoint(osp.join(\"/home/elicer/weight\", f\"{model_name}.ckpt\")).to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_pred = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c07a97a36804c8abda94fc539d294f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a3d0fd0d5b74df0b1e773d5b415da7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0192ff5b3f6a41c998b7e5bd46036e5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for _ in range(23):\n",
    "    pred = []\n",
    "    for data, _ in tqdm(test_dataloader):\n",
    "        with torch.no_grad():\n",
    "            temp = torch.sigmoid(model(data.to(device))).reshape(-1).cpu().numpy().tolist()\n",
    "            pred += temp\n",
    "    total_pred += np.array(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "pred = (total_pred > 0.50).astype(int)\n",
    "print(pred.sum())\n",
    "\n",
    "pred = [\"fake\" if p == 1 else \"real\" for p in pred]\n",
    "submission[\"label\"] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"sample_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
