{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44c41755",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdlib\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'dlib'"
     ]
    }
   ],
   "source": [
    "import easydict\n",
    "import os\n",
    "import sys\n",
    "from PIL import Image\n",
    "import tqdm\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as data\n",
    "from torchvision import transforms\n",
    "import cv2\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import dlib\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a7f190",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = '/mnt/elice/dataset/train'\n",
    "TEST_PATH = '/mnt/elice/dataset/test'\n",
    "\n",
    "train_files = sorted(glob(TRAIN_PATH+'/*/*'))\n",
    "labels = [label.split('/')[-2] for label in train_files]\n",
    "train_df = pd.DataFrame({'path':train_files, 'label':labels})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b6fcb1",
   "metadata": {},
   "source": [
    "## 1) 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19954067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 데이터 경로 및 출력 경로 지정\n",
    "RAW_PATH = \"/mnt/elice/dataset\"\n",
    "PREPROCESSED_PATH = \"/home/elicer/data\"\n",
    "\n",
    "# train 데이터에 대해 전처리 수행\n",
    "\n",
    "def preprocess_worker(path):\n",
    "    try:\n",
    "        global face_classifier\n",
    "        if \"face_classifier\" not in globals():\n",
    "            face_classifier = cv2.CascadeClassifier(\n",
    "                cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\"\n",
    "            )\n",
    "            \n",
    "        cap = cv2.VideoCapture(path[0])\n",
    "        output = cv2.VideoWriter(path[1], cv2.VideoWriter_fourcc('m', 'p', '4', 'v'), cap.get(cv2.CAP_PROP_FPS), (224, 224))\n",
    "        \n",
    "        _, frame = cap.read()\n",
    "        frame = cv2.resize(frame, None, fx=1, fy=10/16)\n",
    "        face_region = face_classifier.detectMultiScale(cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY))\n",
    "        area = [w * h for _, _, w, h in face_region]\n",
    "        \n",
    "        while len(area) == 0:\n",
    "            _, frame = cap.read()\n",
    "            frame = cv2.resize(frame, None, fx=1, fy=10/16)\n",
    "            face_region = face_classifier.detectMultiScale(cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY))\n",
    "            area = [w * h for _, _, w, h in face_region]\n",
    "        \n",
    "        face_region = face_region[area.index(max(area))]\n",
    "\n",
    "        padding_ratio = 1.2\n",
    "        x, y, w, h = face_region\n",
    "        center_x, center_y = x + w // 2, y + h // 2\n",
    "        w, h = w * padding_ratio, h * padding_ratio\n",
    "        x, y = max(center_x - w // 2, 0) , max(center_y - h // 2, 0)\n",
    "\n",
    "        # 제한할 프레임 수 설정\n",
    "        frame_limit = 600\n",
    "        frame_count = 0\n",
    "\n",
    "        while (cap.isOpened()):\n",
    "            ret, frame = cap.read()\n",
    "            if not ret or frame_count >= frame_limit:\n",
    "                break\n",
    "            \n",
    "            frame = cv2.resize(frame, None, fx=1, fy=10/16)\n",
    "            frame = frame[int(y):int(y + h), int(x):int(x + w)]\n",
    "\n",
    "            frame = cv2.resize(frame, (224, 224))\n",
    "            \n",
    "            output.write(frame)\n",
    "            frame_count += 1\n",
    "\n",
    "        cap.release()\n",
    "        output.release()\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}. Skipping video: {path[0]}\")\n",
    "        pass  # 오류가 발생해도 계속해서 진행하기 위해 pass 사용\n",
    "\n",
    "def preprocess(data_type):\n",
    "    if data_type == \"train\":\n",
    "        candidate = [\"fake\", \"real\"]\n",
    "    else:\n",
    "        candidate = \".\"\n",
    "    \n",
    "    for label in candidate:\n",
    "        raw_path = os.path.join(RAW_PATH, data_type, label)\n",
    "        preprocessed_path = os.path.join(PREPROCESSED_PATH, data_type, label)\n",
    "\n",
    "        if not os.path.exists(preprocessed_path):\n",
    "            os.makedirs(preprocessed_path)\n",
    "\n",
    "        raw_paths = os.listdir(raw_path)\n",
    "        raw_paths = [os.path.join(raw_path, path) for path in raw_paths]\n",
    "        preprocess_paths = [os.path.join(preprocessed_path, os.path.basename(path)) for path in raw_paths]\n",
    "\n",
    "        with mp.Pool(mp.cpu_count() - 4) as pool:\n",
    "            list(tqdm(pool.imap(preprocess_worker, zip(raw_paths, preprocess_paths)), total=len(raw_paths)))\n",
    "\n",
    "# train 데이터에 대해 전처리 수행\n",
    "preprocess(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde7bad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = '/home/elicer/data/train'\n",
    "\n",
    "train_crop_files = sorted(glob(TRAIN_PATH+'/*/*'))\n",
    "labels_crop = [label.split('/')[-2] for label in train_crop_files]\n",
    "train_crop_df = pd.DataFrame({'path':train_crop_files, 'label':labels_crop})\n",
    "train_crop_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9c0bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(train_crop_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5a8269",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# train_data에는 이미 비디오 경로와 레이블이 있는 데이터프레임이 있다고 가정합니다.\n",
    "# train_data['path']는 비디오 파일 경로를 담은 열이고, train_data['label']은 레이블 열입니다.\n",
    "# 예를 들어, fake인 경우 label은 0, real인 경우 label은 1로 표시되어 있다고 가정합니다.\n",
    "\n",
    "output_folder = '/home/elicer/img_data'  # 이미지를 저장할 폴더 경로\n",
    "\n",
    "for index, row in tqdm(train_data.iterrows(), total=len(train_data), desc=\"Processing Videos\"):\n",
    "    video_path = row['path']\n",
    "    video_file = os.path.basename(video_path)\n",
    "    label = row['label']  # 레이블 정보 가져오기\n",
    "    \n",
    "    if video_file.endswith('.mp4'):\n",
    "        label_folder = os.path.join(output_folder, 'fake' if label == 'fake' else 'real')\n",
    "        os.makedirs(label_folder, exist_ok=True)  # 레이블 별 폴더 생성\n",
    "\n",
    "        # 비디오를 읽기 위한 OpenCV VideoCapture 객체 초기화\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "        # 비디오 프레임 읽기\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # 프레임 수 및 이미지 수\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        images_per_video = total_frames // 10\n",
    "\n",
    "        for i in range(images_per_video):\n",
    "            for _ in range(10):\n",
    "                ret, frame = cap.read()\n",
    "\n",
    "            if ret:\n",
    "                # 이미지 저장\n",
    "                image_path = os.path.join(label_folder, f\"{video_file.split('.')[0]}_{i}.jpg\")\n",
    "                cv2.imwrite(image_path, frame)\n",
    "\n",
    "        cap.release()  # VideoCapture 객체 해제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20bfdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = '/home/elicer/img_data'\n",
    "\n",
    "img_file = sorted(glob(TRAIN_PATH+'/*/*'))\n",
    "labels_img = [label.split('/')[-2] for label in img_file]\n",
    "img_df = pd.DataFrame({'path':img_file, 'label':labels_img})\n",
    "img_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42a9064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'label' 열의 값을 'fake'는 0으로, 'real'은 1로 변환\n",
    "mapping = {'fake': 0, 'real': 1}\n",
    "img_df['label'] = img_df['label'].replace(mapping)\n",
    "img_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25612fea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b124218",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c419b6cd",
   "metadata": {},
   "source": [
    "## 2) 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8be8c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = easydict.EasyDict({\n",
    "    \"num_workers\": 32,\n",
    "\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"num_epochs\": 1,\n",
    "    \"batch_size\": 32,\n",
    "\n",
    "    \"save_fn\": \"deepfake_c0_xception_tuned.pth.tar\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05be833",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Author: Andreas Rössler,\n",
    "Implemented in https://github.com/ondyari/FaceForensics under MIT license\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class SeparableConv2d(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,kernel_size=1,stride=1,padding=0,dilation=1,bias=False):\n",
    "        super(SeparableConv2d,self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels,in_channels,kernel_size,stride,padding,dilation,groups=in_channels,bias=bias)\n",
    "        self.pointwise = nn.Conv2d(in_channels,out_channels,1,1,0,1,1,bias=bias)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pointwise(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self,in_filters,out_filters,reps,strides=1,start_with_relu=True,grow_first=True):\n",
    "        super(Block, self).__init__()\n",
    "\n",
    "        if out_filters != in_filters or strides!=1:\n",
    "            self.skip = nn.Conv2d(in_filters,out_filters,1,stride=strides, bias=False)\n",
    "            self.skipbn = nn.BatchNorm2d(out_filters)\n",
    "        else:\n",
    "            self.skip=None\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        rep=[]\n",
    "\n",
    "        filters=in_filters\n",
    "        if grow_first:\n",
    "            rep.append(self.relu)\n",
    "            rep.append(SeparableConv2d(in_filters,out_filters,3,stride=1,padding=1,bias=False))\n",
    "            rep.append(nn.BatchNorm2d(out_filters))\n",
    "            filters = out_filters\n",
    "\n",
    "        for i in range(reps-1):\n",
    "            rep.append(self.relu)\n",
    "            rep.append(SeparableConv2d(filters,filters,3,stride=1,padding=1,bias=False))\n",
    "            rep.append(nn.BatchNorm2d(filters))\n",
    "\n",
    "        if not grow_first:\n",
    "            rep.append(self.relu)\n",
    "            rep.append(SeparableConv2d(in_filters,out_filters,3,stride=1,padding=1,bias=False))\n",
    "            rep.append(nn.BatchNorm2d(out_filters))\n",
    "\n",
    "        if not start_with_relu:\n",
    "            rep = rep[1:]\n",
    "        else:\n",
    "            rep[0] = nn.ReLU(inplace=False)\n",
    "\n",
    "        if strides != 1:\n",
    "            rep.append(nn.MaxPool2d(3,strides,1))\n",
    "        self.rep = nn.Sequential(*rep)\n",
    "\n",
    "    def forward(self,inp):\n",
    "        x = self.rep(inp)\n",
    "\n",
    "        if self.skip is not None:\n",
    "            skip = self.skip(inp)\n",
    "            skip = self.skipbn(skip)\n",
    "        else:\n",
    "            skip = inp\n",
    "\n",
    "        x+=skip\n",
    "        return x\n",
    "\n",
    "\n",
    "class Xception(nn.Module):\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(Xception, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3,32,3,2,0,bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32,64,3,bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.block1=Block(64,128,2,2,start_with_relu=False,grow_first=True)\n",
    "        self.block2=Block(128,256,2,2,start_with_relu=True,grow_first=True)\n",
    "        self.block3=Block(256,728,2,2,start_with_relu=True,grow_first=True)\n",
    "\n",
    "        self.block4=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n",
    "        self.block5=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n",
    "        self.block6=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n",
    "        self.block7=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n",
    "\n",
    "        self.block8=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n",
    "        self.block9=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n",
    "        self.block10=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n",
    "        self.block11=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n",
    "\n",
    "        self.block12=Block(728,1024,2,2,start_with_relu=True,grow_first=False)\n",
    "\n",
    "        self.conv3 = SeparableConv2d(1024,1536,3,1,1)\n",
    "        self.bn3 = nn.BatchNorm2d(1536)\n",
    "\n",
    "        self.conv4 = SeparableConv2d(1536,2048,3,1,1)\n",
    "        self.bn4 = nn.BatchNorm2d(2048)\n",
    "\n",
    "        self.fc = nn.Linear(2048, num_classes)\n",
    "\n",
    "    def features(self, input):\n",
    "        x = self.conv1(input)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        x = self.block5(x)\n",
    "        x = self.block6(x)\n",
    "        x = self.block7(x)\n",
    "        x = self.block8(x)\n",
    "        x = self.block9(x)\n",
    "        x = self.block10(x)\n",
    "        x = self.block11(x)\n",
    "        x = self.block12(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = self.bn4(x)\n",
    "        return x\n",
    "\n",
    "    def logits(self, features):\n",
    "        x = self.relu(features)\n",
    "\n",
    "        x = F.adaptive_avg_pool2d(x, (1, 1)) \n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.last_linear(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.features(input)\n",
    "        x = self.logits(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "## 기존 Xception에 Dropout만 추가\n",
    "class xception(nn.Module):\n",
    "    def __init__(self, num_out_classes=2, dropout=0.5):\n",
    "        super(xception, self).__init__()\n",
    "\n",
    "        self.model = Xception(num_classes=num_out_classes)\n",
    "        self.model.last_linear = self.model.fc\n",
    "        del self.model.fc\n",
    "\n",
    "        num_ftrs = self.model.last_linear.in_features\n",
    "        if not dropout:\n",
    "            self.model.last_linear = nn.Linear(num_ftrs, num_out_classes)\n",
    "        else:            \n",
    "            self.model.last_linear = nn.Sequential(\n",
    "                nn.Dropout(p=dropout),\n",
    "                nn.Linear(num_ftrs, num_out_classes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5afad12",
   "metadata": {},
   "outputs": [],
   "source": [
    "xception_default = {\n",
    "    'train': transforms.Compose([transforms.ToTensor(),\n",
    "                                 transforms.Resize((224, 224)),\n",
    "                                 transforms.RandomHorizontalFlip(),\n",
    "                                 transforms.Normalize([0.5]*3, [0.5]*3),\n",
    "                                 ]),\n",
    "    'valid': transforms.Compose([transforms.ToTensor(),\n",
    "                                 transforms.Resize((224, 224)),\n",
    "                                 transforms.Normalize([0.5]*3, [0.5]*3),\n",
    "                                 ]),\n",
    "    'test': transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Resize((224, 224)),\n",
    "                                transforms.Normalize([0.5] * 3, [0.5] * 3),\n",
    "                                ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5000e5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# util\n",
    "\n",
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch, args):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = args.lr * (0.1 ** (epoch // 30))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2a859b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DFDCDatatset(data.Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def _load_image(self, image_path):\n",
    "        return Image.open(image_path).convert('RGB')\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        label = int(self.dataframe.iloc[index]['label'])\n",
    "        image = self._load_image(img_df.iloc[index]['path'])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed4b35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train / validate\n",
    "\n",
    "def train(train_loader, model, criterion, optimizer, epoch):   \n",
    "    n = 0\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    with tqdm(train_loader, total=len(train_loader), desc=\"Train\", file=sys.stdout) as iterator:\n",
    "        for images, target in iterator:\n",
    "            images = images.cuda()\n",
    "            target = target.cuda()\n",
    "        \n",
    "            outputs = model(images)\n",
    "            _, pred = torch.max(outputs.data, 1)\n",
    "\n",
    "            loss = criterion(outputs, target)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            n += images.size(0)\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            running_corrects += torch.sum(pred == target.data)\n",
    "\n",
    "            epoch_loss = running_loss / float(n)\n",
    "            epoch_acc = running_corrects / float(n)\n",
    "\n",
    "            log = 'loss - {:.4f}, acc - {:.3f}'.format(epoch_loss, epoch_acc)\n",
    "            iterator.set_postfix_str(log)\n",
    "\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347c4b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xception(num_out_classes=2, dropout=0.5).cuda()\n",
    "print(\"=> creating model '{}'\".format('xception'))\n",
    "# model = model()\n",
    "\n",
    "fn = 'deepfake_c0_xception.pkl'\n",
    "assert os.path.isfile(fn), 'wrong path'\n",
    "\n",
    "model.load_state_dict(torch.load(fn))\n",
    "print(\"=> model weight '{}' is loaded\".format(fn))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d370fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DFDCDatatset(img_df, transform=xception_default[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656b0693",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           batch_size=args.batch_size,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=args.num_workers,\n",
    "                                           pin_memory=True,\n",
    "                                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6edd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## overfit을 막기 위하여 한 번만 학습\n",
    "print('-' * 50)\n",
    "print('Epoch {}/{}'.format(1, args.num_epochs))\n",
    "train(train_loader, model, criterion, optimizer, 0)\n",
    "acc = validate(valid_loader, model, criterion)\n",
    "\n",
    "save_checkpoint(state={'epoch': args.num_epochs + 1,\n",
    "                       'state_dict': model.state_dict(),\n",
    "                       'best_acc1': acc,\n",
    "                       'optimizer': optimizer.state_dict(),},\n",
    "                is_best=False,\n",
    "                filename=args.save_fn,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a526eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295e220c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d672e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
